\documentclass[a4paper,11pt]{article}

\usepackage{graphicx, url}

%--Title---------
\title{Software Evolution - Assignment 4 : Testing and repository mining}
\author{Stef van Schuylenburg (0744314) \& Jules Wulms (0747580)}
\date{\today}
%----------------

\begin{document}

	\maketitle

	\section{Introduction}
		In this assignment we look into social coding and continuous integration. We try to find out how continuous integration, which comes down to building and testing, is done in various GitHub \cite{github} projects and whether we can derive a relation between the way in which changes are introduced to a GitHub repository and the chance of the corresponding build to fail. \\

		In order to get all the information we want, we use a couple of tools. GHTorrent \cite{ghtorrent} provides a MySQL database, which we can use to query the metadata of GitHub repositories. We use several MySQL queries to get data for all large and active independent projects. Information about the continuous integration of these projects, we get using Travis CI \cite{travis}. Travis CI is a distributed continuous integration service for projects hosted at GitHub. We can get information about the builds using the API provided by the official Travis CI web interface. When we have extracted all the data, we use R \cite{rstatistic} to do a statistical analysis on the data. \\

		The report has the following structure: In Section 2 we elaborate on the systems we are analyzing, namely GitHub and Travis CI, to provide some insight in what we are investigating. Section 3 is about the methodology of our research and an in-depth look into the tools and programs we use to get our results. Section 4 describes our results and what facts we can derive from them. In Section 5 we discuss threads that can invalidate our research. The report ends with conclusions we can draw from looking into repositories and continuous integration, and their relation to evolution.
	
	\section{Background}
		As stated in the previous section, we look at repositories on Github and we want to get information about the build
		made by Travis CI.
		
		\subsection{GitHub}
			Github\cite{github} is a platform that is build around the version control system git.
			It allows users to host their git repositories and it supplies a web interface for browsing through repositories and
			to manage repositories.
			Github calls their platform \emph{social coding}, by which they mean that they want to provide services such that
			developers can easily share code, discuss changes and collaborate.
			Github is very popular for open source projects, but it is also used for commercial projects, where companies can pay
			to create private projects.
			At the moment of writing Github is the largest code host and hosts over 11.8 million repositories.
			
			One particular feature of Github we look at in this assignment are the pull requests: 
			For git normal changes are saved as commits (similar to other version control systems),
			but Github allows users to group a number of commits as a pull requests, which must be first accepted before the
			changes are applied to the main version of the repository.
			Those pull requests are introduced such that the changes can be checked on quality before commiting them to the main
			version.
		
		\subsection{Travis CI}
		  Travis CI\cite{travis} is a Continuous Integration system for github.
		  Travis is used to automatically build and test Github project each time a commit has been made or a pull request
		  is accepted.
		  Everytime a build is done, Travis shows the state and keeps a history of the builds which we use in this assignment
		  to do calculations with.
		  Travis is used primarly for open source projects as the main version of Travis does not support private
		  repositories.
		  There is a version of Travis, that does support private repositories, but this system is not widely used yet.
		  
		  
		
	\section{Methodology}
		Now that we know what we are looking into, we can proceed by elaborating on what steps we have to take to extract and analyse data from the systems we are considering. The process consists of three steps: extracting data about GitHub projects throught GHTorrent's MySQL database, extracting continuous integration data via Travis CI, and doing statistical tests using R. Each of the following subsections will elaborate on a different part of this process.
		
		\subsection{Identifying GitHub projects}
			We want to extract data about GitHub projects using the GHTorrent MySQL database. The database is has a web interface available at \url{http://ghtorrent.org/dblite/}. For the later analysis, it is important to make the amount of projects managable, and in order to get useful data, we query only specific projects, which are "large and active independent projects". The projects we want all have to meet following requirements, such that they:

			\begin{enumerate}
				\item are not forks of other repositories,
				\item have not been deleted,
				\item have at least 10 different contributors,
				\item have at least 10 changes during the previous month, where changes are commits or pull requests,
				\item are at least one year old,
				\item have both commits and pull requests,
				\item have been developed in Java, Python or Ruby.
			\end{enumerate}
	
			In one big query, we are able to fullfil all the requirements, except the forth requirement. The main query can be found Appendix \ref{app:mainquery}, it has a statement/subquery in the where clause for each of the other requirements. The forth requirement needs further processing of the commit and pull request tables in the database, which are really big tables. Processing these tables in the main query is very inefficient and results in very long running times. Since the web interface of GHTorrent's MySQL database was very unstable, when we used it, we decided against a query with too long running times. The alternative was smaller helper queries for the more complex data we wanted to extract, which involved counting rows. The queries are shown in Appendix \ref{app:mainquery} and use the main query as a source of pruning the id values of the projects that have to be considered.\\

			When all the data is extracted from the GHTorrents database, we put the extracted .csv-files in an Excel-file, and use the VLOOKUP-function in Microsoft Excel to combine the results of the same projects, using their id values. When all the results are combined, we add the number of commits and pull requests in a new column to get the changes that we need for requirement 4. Then we can easily sort the table on this changes column, and delete all entries that have a value lower than 10. At this point, we have identified the large and active independent projects, and have already gathered a big chunk of data about them.

		\subsection{Travis CI extraction}
			In the next step we want information about the builds of the Github project.
			For this we use a Ruby library from the Travis CI Client\cite{travis.rb}.
			This library gives us access to information about the builds in Travis CI of a Github project.
			To use this library we need the slugs of the github repositories.
			The slug is a part of the URL to the github, in which the user and the repository name are used (for example for the
			Travis CI Client this would be \texttt{travis-ci/travis.rb}).
			To get those slugs we read the comma seperated values file, containing all the Github projects that met the
			requirements and we extract the slugs from the \texttt{url} collumn in that file (we extract the slug using regular
			expressions).
			
			Now we got all the slugs, we can use the Travis CI Client library to try to find the Github project in Travis.
			If we find the project in Travis then we go through the build history and count the number of passed and failed
			builds for both the pull requests and the commits (we count all the values separated, so we end with four different
			values).
			Then we look for the Travis CI identifier correspending to this Github project.
			
			And in the end we write for all the Github repositories which we can find in Travis CI the Travic CI identifier and
			the build values to a comma seperated values file, such that we can use it in R for the statistical analysis.
			
			% TODO: do we add the Ruby script as appendix or do we add it on Peach?
			The Ruby script we used to extract the information from Travic CI is delivered together with this assignment.
	
		\subsection{Statistical analysis}
			The  
	
	\section{Results and discussion}
		In this section we will present our results and discuss their meaning. We start by looking into the raw data that we collected and after that look further into the results of our statistical analysis.
		
		\subsection{Data}
			First we will look into the GitHub data that we extracted from the GHTorrent database. We have identified 1839 projects in the main query, of which 223 had enough commits and pull request in the last month, to be considered in the rest of the analysis. An important fact is that we use \texttt{NOW()} in the queries, which makes them dependent on the moment they were executed. We ran all the queries the 30th of March 2014. Of the 223 projects that we are going to check Travis CI data for, 70 are developed in Java, 83 in Python and 73 in Ruby. Java projects seem too use the least pull requests in the last month, with a maximum of 26 and the most projects that use no pull request out of the 3 languages. Python and Ruby both have higher amounts of pull requests, with maxima of 97 and 236 respectively, and less projects that use no pull requests. Some Python and Ruby projects even have more pull requests than commits. \\

			The Shared Repository Model of GitHub is more popular for Java projects, while Python and Ruby projects have more users sending pull requests. A reason for this could be that Python and Ruby are scripting languages, of which projects are probably more sought after by webdevelopers. Web developers usually promote usages of existing functionality and building your own project out of existing building blocks. In this process, bugs can be found or useful functionality can be added to the fork, which can lead to more pull requests. Overall, we see that commits (direct code modification) is more popular than pull requests (indirect code modification), with only a small amount of projects having more pull requests than commits. \\

			travis data \\

			R data
			
		\subsection{Analysis}
			Now 
			
	\section{Threads to validity}
		Now 
	
	\section{Conclusions}
		W.

	\appendix
	\section{Main query}
	\label{app:mainquery}
	This is the main query to get a list of GitHub repositories that meet all requirements for large and active independent repositories, except for one: at least 10 changes (commits/pull requests) in the past month. The SELECT-statement is big to extract as much data as we can for the analysis.
	
	{\scriptsize
	\begin{verbatim}
SELECT id, url, name, language, 
       TIMESTAMPDIFF(day, DATE_FORMAT(projects.created_at,"\%Y-\%m-\%d"), "2014-03-06") as age_days 
FROM projects 
WHERE -- not deleted
      projects.deleted = 0 AND 
      -- not a fork of another project
      projects.forked_from IS NULL AND 
      -- at least 1 year old
      projects.created_at <= DATE_SUB(NOW(),INTERVAL 1 YEAR) AND 
      -- written in Java/Ruby/Python
     (projects.language = "Java" OR projects.language = "Ruby" OR projects.language = "Python") AND 
      -- at least 10 different users
      EXISTS (SELECT COUNT(DISTINCT user_id) as usercount 
              FROM project_members 
              WHERE project_members.repo_id = projects.id  
              HAVING usercount >= 10) AND 
      -- at least 1 commit and 1 pull request
      EXISTS (SELECT pull_requests.id, commits.id 
              FROM pull_requests, commits 
              WHERE pull_requests.base_repo_id = projects.id AND 
                    commits.project_id = projects.id);
	\end{verbatim}
	}
	
	\section{Helper queries}
	\label{app:helpquery}
	The helper queries fullfill the requirement that was not met in the main query, and some queries get extra data for the analysis. All the queries use the main query as a way to find a smaller set of project id's to check. However, the main query as subquery was too complex for the commits helper query, since the commits table has over 90 million entries. There we used a list of comma separated id values, custom made by copying the id column of the main query, and replacing newlines by commas, using Notepad++.
	
	{\scriptsize
	\begin{verbatim}
-- amount of contributors per repo (using unfiltered id's)
SELECT repo_id, COUNT(user_id) as contributors 
FROM project_members 
WHERE repo_id IN (SELECT id  
                  FROM projects 
                  WHERE projects.deleted = 0 AND 
                        projects.forked_from IS NULL AND 
                        projects.created_at <= DATE_SUB(NOW(),INTERVAL 1 YEAR) AND 
                       (projects.language = "Java" OR projects.language = "Ruby" OR 
                        projects.language = "Python") AND 
                        EXISTS (SELECT COUNT(DISTINCT user_id) as usercount 
                                FROM project_members 
                                WHERE project_members.repo_id = projects.id  
                                HAVING usercount >= 10) AND 
                        EXISTS (SELECT pull_requests.id, commits.id 
                                FROM pull_requests, commits 
                                WHERE pull_requests.base_repo_id = projects.id AND 
                                      commits.project_id = projects.id)) 
GROUP BY repo_id 
ORDER BY repo_id ASC;

-- amount of pull requests last month (using unfiltered id's)
SELECT base_repo_id, COUNT(pull_requests.id) as pull_reqs_last_month 
FROM pull_requests, pull_request_history 
WHERE pull_requests.id = pull_request_history.pull_request_id AND 
      pull_request_history.action = "opened" and 
      pull_request_history.created_at >= DATE_SUB(NOW(), INTERVAL 1 MONTH) AND 
      pull_requests.base_repo_id IN (SELECT id 
                  FROM projects 
                  WHERE projects.deleted = 0 AND 
                        projects.forked_from IS NULL AND 
                        projects.created_at <= DATE_SUB(NOW(),INTERVAL 1 YEAR) AND 
                       (projects.language = "Java" OR projects.language = "Ruby" OR 
                        projects.language = "Python") AND 
                        EXISTS (SELECT COUNT(DISTINCT user_id) as usercount 
                                FROM project_members 
                                WHERE project_members.repo_id = projects.id 
                                HAVING usercount >= 10) AND 
                        EXISTS (SELECT pull_requests.id, commits.id 
                                FROM pull_requests, commits 
                                WHERE pull_requests.base_repo_id = projects.id AND 
                                      commits.project_id = projects.id)) 
GROUP BY base_repo_id 
ORDER BY base_repo_id ASC;

-- amount of commits last month (using unfiltered id's)
SELECT project_id, COUNT(id) as commits_last_month 
FROM commits 
WHERE commits.created_at >= DATE_SUB(NOW(), INTERVAL 1 MONTH) AND 
      project_id IN (--id's--) 
GROUP BY project_id 
ORDER BY project_id ASC;
	\end{verbatim}
	}

	\begin{thebibliography}{9}
		\bibitem{github}
			GitHub, Web-based hosting service for software development projects using Git revision control, https://github.com/

		\bibitem{ghtorrent}
			Gousios, Georgios, The GHTorrent dataset and tool suite, 
			Proceedings of the 10th Working Conference on Mining Software Repositories, MSR '13,
			San Francisco, CA, USA, IEEE Press, 2013

		\bibitem{travis}
			Travis CI, a hosted, distributed continuous integration service for GitHub projects, https://travis-ci.org/

		\bibitem{rstatistic}
			R, language and environment for statistical computing and graphics, http://http://www.r-project.org/
			
		\bibitem{travis.rb}
		  The Travis CI client, a tool (both a command line client and a Ruby library) to interface with a Travis CI service,
		  https://github.com/travis-ci/travis.rb
		
	\end{thebibliography}

\end{document}