\documentclass[a4paper,11pt]{article}

\usepackage{graphicx, url}

%--Title---------
\title{Software Evolution - Assignment 4 : Testing and repository mining}
\author{Stef van Schuylenburg (0744314) \& Jules Wulms (0747580)}
\date{\today}
%----------------

\begin{document}

	\maketitle

	\section{Introduction}
		In this assignment we look into social coding and continuous integration. We try to find out how continuous integration, which comes down to building and testing, is done in various GitHub \cite{github} projects and whether we can derive a relation between the way in which changes are introduced to a GitHub repository and the chance of the corresponding build to fail. \\

		In order to get all the information we want, we use a couple of tools. GHTorrent \cite{ghtorrent} provides a MySQL database, which we can use to query the metadata of GitHub repositories. We use several MySQL queries to get data for all large and active independent projects. Information about the continuous integration of these projects, we get using Travis CI \cite{travis}. Travis CI is a distributed continuous integration service for projects hosted at GitHub. We can get information about the builds using the API provided by the official Travis CI web interface. When we have extracted all the data, we use R \cite{rstatistic} to do a statistical analysis on the data. \\

		The report has the following structure: In Section 2 we elaborate on the systems we are analyzing, namely GitHub and Travis CI, to provide some insight in what we are investigating. Section 3 is about the methodology of our research and an in-depth look into the tools and programs we use to get our results. Section 4 describes our results and what facts we can derive from them. In Section 5 we discuss threads that can invalidate our research. The report ends with conclusions we can draw from looking into repositories and continuous integration, and their relation to evolution.
	
	\section{Background}
		The general approach of our tool chain is that we take a Java project as input and give a visualized UML class diagram of this Java project as output. In this section we look at the input and output in more detail to indicate what our tool chain exactly accepts and what it returns.
		
		\subsection{GitHub}
			We
		
		\subsection{Travis CI}
			The 
		
	\section{Methodology}
		Now that we know what we are looking into, we can proceed by elaborating on what steps we have to take to extract and analyse data from the systems we are considering. The process consists of three steps: extracting data about GitHub projects throught GHTorrent's MySQL database, extracting continuous integration data via Travis CI, and doing statistical tests using R. Each of the following subsections will elaborate on a different part of this process.
		
		\subsection{Identifying GitHub projects}
			We
	
		\subsection{Travis CI extraction}
			The 
	
		\subsection{Statistical analysis}
			The  
	
	\section{Results and discussion}
		The tool chain is developed for reconstructing architectures, so we applied it on some Java projects to see how it performs and to address the evolution of an existing Java project. In this section we will first compare the results of our own tool chain to the results shown in in the book by Tonella and Potrich, and after that look into the evolution of CyberNeko HTML Parser, by reconstructing the architecture of 2 versions of the project.
		
		\subsection{Data}
			We.
			
		\subsection{Analysis}
			Now 
			
	\section{Threads to validity}
		Now 
	
	\section{Conclusions}
		We can conclude that architecture reconstruction is a nice way of getting insight in the evolution of a software project. All you need to do is reconstruct the architecture of different versions of a project and you have a convenient way of manually comparing the versions. Also using the right tools, it is not too hard to create a tool chain that does this reconstruction in a nice way. However, the more information you want to reconstruct in the diagram, and the nicer you want the diagram to be, the harder it is to get things right. Performance issues, and messy diagrams are the most apparant limitations to architecture reconstruction. We see this as a tradeoff: Having more complex features/visualization will require more computational power, but leaving out features will make room for other features to be more complex and computational demanding.

	\appendix
	\section{Queries}
		blabla

	\begin{thebibliography}{9}
		\bibitem{github}
			GitHub, Web-based hosting service for software development projects using Git revision control, https://github.com/

		\bibitem{ghtorrent}
			Gousios, Georgios, The GHTorrent dataset and tool suite, 
			Proceedings of the 10th Working Conference on Mining Software Repositories, MSR '13,
			San Francisco, CA, USA, IEEE Press, 2013

		\bibitem{travis}
			Travis CI, a hosted, distributed continuous integration service for GitHub projects, https://travis-ci.org/

		\bibitem{rstatistic}
			R, language and environment for statistical computing and graphics, http://http://www.r-project.org/
		
	\end{thebibliography}

\end{document}